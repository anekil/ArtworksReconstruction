{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "from UNN.superresolution.SuperResolutionTrainer import SuperResolutionTrainer\n",
    "from UNN.superresolution.SuperResolutionDataset import SuperResolutionDataset\n",
    "from UNN.impainting.InpaintingTrainer import InpaintingTrainer\n",
    "from UNN.autoencoder.autoencoder import ResNet50Autoencoder\n",
    "from UNN.impainting.InpaintingDataset import InpaintingDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"comet_api_key\": \"lliw2sljNWoBqtmqb9KztyYsG\",\n",
    "    \"project_name\": \"image_inpainting\",\n",
    "    \"model_save_path\": \"./models\",\n",
    "    \"max_epochs\": 1,\n",
    "    \"patience\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 1e-4\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df = pd.read_parquet('local_wikiart.parquet', columns=['title', 'artist', 'date', 'genre', 'style', 'image'])\n",
    "df = df.head(100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/adrian-rochminski/image-inpainting/16ef405098134f29b22f478fcd9d5c07\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Adrian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Adrian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Adrian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 419, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Adrian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 419, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Adrian\\Desktop\\Semestr_2_mg\\un\\UNN\\impainting\\InpaintingDataset.py\", line 27, in __getitem__\n    damaged_image = apply_damage(image)\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Adrian\\Desktop\\Semestr_2_mg\\un\\UNN\\impainting\\InpaintingDataset.py\", line 16, in apply_damage\n    img[top_left_y:top_left_y + mask_size, top_left_x:top_left_x + mask_size] = [255, 255, 255]\n    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not broadcast input array from shape (3,) into shape (0,0,224)\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 17\u001B[0m\n\u001B[0;32m     14\u001B[0m trainer \u001B[38;5;241m=\u001B[39m InpaintingTrainer(model, dataset, config)\n\u001B[0;32m     16\u001B[0m \u001B[38;5;66;03m# Start training\u001B[39;00m\n\u001B[1;32m---> 17\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\Semestr_2_mg\\un\\UNN\\impainting\\InpaintingTrainer.py:87\u001B[0m, in \u001B[0;36mInpaintingTrainer.train\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     84\u001B[0m epoch_start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     86\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 87\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mdamaged_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moriginal_images\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_start_time\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtime\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdamaged_images\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdamaged_images\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[0;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1346\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1344\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1345\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[1;32m-> 1346\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1372\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[1;34m(self, data)\u001B[0m\n\u001B[0;32m   1370\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[0;32m   1371\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[1;32m-> 1372\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1373\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_utils.py:705\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    701\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m    702\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[0;32m    703\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m--> 705\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[1;31mValueError\u001B[0m: Caught ValueError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"C:\\Users\\Adrian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Adrian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\", line 49, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Adrian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 419, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Adrian\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataset.py\", line 419, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n            ~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Adrian\\Desktop\\Semestr_2_mg\\un\\UNN\\impainting\\InpaintingDataset.py\", line 27, in __getitem__\n    damaged_image = apply_damage(image)\n                    ^^^^^^^^^^^^^^^^^^^\n  File \"C:\\Users\\Adrian\\Desktop\\Semestr_2_mg\\un\\UNN\\impainting\\InpaintingDataset.py\", line 16, in apply_damage\n    img[top_left_y:top_left_y + mask_size, top_left_x:top_left_x + mask_size] = [255, 255, 255]\n    ~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not broadcast input array from shape (3,) into shape (0,0,224)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Create dataset\n",
    "dataset = InpaintingDataset(df, transform=transform)\n",
    "\n",
    "# Initialize model\n",
    "model = ResNet50Autoencoder(latent_dim=256, freeze_percentage=0.8)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = InpaintingTrainer(model, dataset, config)\n",
    "\n",
    "# Start training\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/adrian-rochminski/image-inpainting/c006013403ba49429a69c40495289085\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "Train Epoch: 1 [32/70 (0%)]\tLoss: 0.473536\tTime: 7.67s\n",
      "Train Epoch: 1 [64/70 (33%)]\tLoss: 0.483785\tTime: 6.16s\n",
      "Train Epoch: 1 [70/70 (67%)]\tLoss: 0.345814\tTime: 1.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SuperResolutionTrainer:Epoch 1: Avg Train Loss = 0.434379, Avg Val Loss = 0.288341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed in 83.22s - Avg Train Loss: 0.434379, Avg Val Loss: 0.288341\n",
      "Validation loss decreased (0.288341). Saving model...\n",
      "Logged 5 images for Epoch 1\n",
      "\n",
      "Starting testing phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SuperResolutionTrainer:Test Loss: 0.300984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.300984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m Passed step value 'test' is not a number, ignoring it\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m Passed step value 'test' is not a number, ignoring it\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m Passed step value 'test' is not a number, ignoring it\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m Passed step value 'test' is not a number, ignoring it\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m Passed step value 'test' is not a number, ignoring it\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Comet.ml Experiment Summary\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Data:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     display_summary_level : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     name                  : bright_roadrunner_6568\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     url                   : https://www.comet.com/adrian-rochminski/image-inpainting/c006013403ba49429a69c40495289085\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Metrics [count] (min, max):\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     batch_time [3]       : (1.3869483470916748, 7.667745351791382)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     batch_train_loss [3] : (0.3458144962787628, 0.4837852120399475)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     epoch_train_loss     : 0.4343785246213277\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     epoch_val_loss       : 0.2883407771587372\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     test_loss            : 0.30098381638526917\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Parameters:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     batch_size      : 32\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     comet_api_key   : lliw2sljNWoBqtmqb9KztyYsG\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     learning_rate   : 0.0001\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     max_epochs      : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     model_save_path : ./models\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     patience        : 5\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     project_name    : image_inpainting\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Uploads:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     environment details : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     filename            : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     git metadata        : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     images              : 10\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     installed packages  : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     notebook            : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     source_code         : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     text-sample         : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged 5 images for Epoch test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Uploading 1 metrics, params and output messages\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m All assets have been sent, waiting for delivery confirmation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "dataset = SuperResolutionDataset(df, transform=transform, upscale_factor=2)\n",
    "\n",
    "# Initialize model\n",
    "model = ResNet50Autoencoder(latent_dim=256, freeze_percentage=0.8)\n",
    "\n",
    "# Initialize trainer\n",
    "trainer = SuperResolutionTrainer(model, dataset, config)\n",
    "\n",
    "# Start training\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
