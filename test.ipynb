{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-16T09:40:13.613243Z",
     "start_time": "2024-12-16T09:40:09.568867Z"
    }
   },
   "source": [
    "from torchvision import models, transforms\n",
    "import pandas as pd\n",
    "from superresolution.SuperResolutionTrainer import SuperResolutionTrainer\n",
    "from superresolution.SuperResolutionDataset import SuperResolutionDataset\n",
    "from inpainting.InpaintingTrainer import InpaintingTrainer\n",
    "from autoencoder.autoencoder import ResNet50Autoencoder\n",
    "from inpainting.InpaintingDataset import InpaintingDataset"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "config = {\n",
    "    \"comet_api_key\": \"lliw2sljNWoBqtmqb9KztyYsG\",\n",
    "    \"project_name\": \"image_inpainting\",\n",
    "    #\"model_save_path\": \"./models\",\n",
    "    \"max_epochs\": 10,\n",
    "    \"patience\": 5,\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 1e-4\n",
    "}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T09:40:13.619630Z",
     "start_time": "2024-12-16T09:40:13.617012Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_parquet('local_wikiart.parquet', columns=['title', 'artist', 'date', 'genre', 'style', 'image']).head(9000)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-12-16T09:40:14.987993Z",
     "start_time": "2024-12-16T09:40:13.697648Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "dataset = InpaintingDataset(df, transform=transform)\n",
    "model = ResNet50Autoencoder(latent_dim=256, freeze_percentage=0.8)\n",
    "trainer = InpaintingTrainer(model, dataset, config)\n",
    "trainer.train()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2024-12-16T09:40:22.816742Z",
     "start_time": "2024-12-16T09:40:15.083125Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/adrian-rochminski/image-inpainting/02a946dc7a814e6187e498a55e1e35e7\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/PIL/Image.py\", line 3437, in open\n    fp.seek(0)\nAttributeError: 'dict' object has no attribute 'seek'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/home/aneta/Documents/UNN/inpainting/InpaintingDataset.py\", line 25, in __getitem__\n    image = Image.open(img_bytes).convert(\"RGB\")\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/PIL/Image.py\", line 3439, in open\n    fp = io.BytesIO(fp.read())\nAttributeError: 'dict' object has no attribute 'read'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 9\u001B[0m\n\u001B[1;32m      7\u001B[0m model \u001B[38;5;241m=\u001B[39m ResNet50Autoencoder(latent_dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m256\u001B[39m, freeze_percentage\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.8\u001B[39m)\n\u001B[1;32m      8\u001B[0m trainer \u001B[38;5;241m=\u001B[39m InpaintingTrainer(model, dataset, config)\n\u001B[0;32m----> 9\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UNN/inpainting/InpaintingTrainer.py:101\u001B[0m, in \u001B[0;36mInpaintingTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     98\u001B[0m epoch_start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m--> 101\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch_idx, (damaged_images, original_images) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[1;32m    102\u001B[0m     batch_start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m    104\u001B[0m     damaged_images \u001B[38;5;241m=\u001B[39m damaged_images\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[0;32m~/Documents/UNN/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[1;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[1;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[1;32m    707\u001B[0m ):\n",
      "File \u001B[0;32m~/Documents/UNN/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1465\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1463\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1464\u001B[0m     \u001B[38;5;28;01mdel\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[idx]\n\u001B[0;32m-> 1465\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/UNN/venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1491\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1489\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[1;32m   1490\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[0;32m-> 1491\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m~/Documents/UNN/venv/lib/python3.10/site-packages/torch/_utils.py:715\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    711\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m    712\u001B[0m     \u001B[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001B[39;00m\n\u001B[1;32m    713\u001B[0m     \u001B[38;5;66;03m# instantiate since we don't know how to\u001B[39;00m\n\u001B[1;32m    714\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(msg) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 715\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m exception\n",
      "\u001B[0;31mAttributeError\u001B[0m: Caught AttributeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/PIL/Image.py\", line 3437, in open\n    fp.seek(0)\nAttributeError: 'dict' object has no attribute 'seek'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 351, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 50, in fetch\n    data = self.dataset.__getitems__(possibly_batched_index)\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 420, in __getitems__\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/torch/utils/data/dataset.py\", line 420, in <listcomp>\n    return [self.dataset[self.indices[idx]] for idx in indices]\n  File \"/home/aneta/Documents/UNN/inpainting/InpaintingDataset.py\", line 25, in __getitem__\n    image = Image.open(img_bytes).convert(\"RGB\")\n  File \"/home/aneta/Documents/UNN/venv/lib/python3.10/site-packages/PIL/Image.py\", line 3439, in open\n    fp = io.BytesIO(fp.read())\nAttributeError: 'dict' object has no attribute 'read'\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Experiment is live on comet.com https://www.comet.com/adrian-rochminski/image-inpainting/c006013403ba49429a69c40495289085\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1\n",
      "Train Epoch: 1 [32/70 (0%)]\tLoss: 0.473536\tTime: 7.67s\n",
      "Train Epoch: 1 [64/70 (33%)]\tLoss: 0.483785\tTime: 6.16s\n",
      "Train Epoch: 1 [70/70 (67%)]\tLoss: 0.345814\tTime: 1.39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SuperResolutionTrainer:Epoch 1: Avg Train Loss = 0.434379, Avg Val Loss = 0.288341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed in 83.22s - Avg Train Loss: 0.434379, Avg Val Loss: 0.288341\n",
      "Validation loss decreased (0.288341). Saving model...\n",
      "Logged 5 images for Epoch 1\n",
      "\n",
      "Starting testing phase...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:SuperResolutionTrainer:Test Loss: 0.300984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.300984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m Passed step value 'test' is not a number, ignoring it\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m Passed step value 'test' is not a number, ignoring it\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m Passed step value 'test' is not a number, ignoring it\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m Passed step value 'test' is not a number, ignoring it\n",
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m Passed step value 'test' is not a number, ignoring it\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Comet.ml Experiment Summary\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m ---------------------------------------------------------------------------------------\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Data:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     display_summary_level : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     name                  : bright_roadrunner_6568\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     url                   : https://www.comet.com/adrian-rochminski/image-inpainting/c006013403ba49429a69c40495289085\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Metrics [count] (min, max):\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     batch_time [3]       : (1.3869483470916748, 7.667745351791382)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     batch_train_loss [3] : (0.3458144962787628, 0.4837852120399475)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     epoch_train_loss     : 0.4343785246213277\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     epoch_val_loss       : 0.2883407771587372\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     test_loss            : 0.30098381638526917\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Parameters:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     batch_size      : 32\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     comet_api_key   : lliw2sljNWoBqtmqb9KztyYsG\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     learning_rate   : 0.0001\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     max_epochs      : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     model_save_path : ./models\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     patience        : 5\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     project_name    : image_inpainting\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m   Uploads:\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     environment details : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     filename            : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     git metadata        : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     images              : 10\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     installed packages  : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     notebook            : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     source_code         : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m     text-sample         : 1\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged 5 images for Epoch test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[1;38;5;214mCOMET WARNING:\u001B[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Uploading 1 metrics, params and output messages\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m Please wait for assets to finish uploading (timeout is 10800 seconds)\n",
      "\u001B[1;38;5;39mCOMET INFO:\u001B[0m All assets have been sent, waiting for delivery confirmation\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "\n",
    "dataset = SuperResolutionDataset(df, transform=transform, upscale_factor=2)\n",
    "model = ResNet50Autoencoder(latent_dim=256, freeze_percentage=0.8)\n",
    "trainer = SuperResolutionTrainer(model, dataset, config)\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
